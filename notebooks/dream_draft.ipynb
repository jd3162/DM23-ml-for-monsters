{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd532aad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Here's our N-gram model: what we have so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66071bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk import ConditionalFreqDist\n",
    "from nltk.probability import ConditionalProbDist, ELEProbDist\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b86ba",
   "metadata": {},
   "source": [
    "2. numbers are a problem for n-gram models becayse there are so many of them. we don't want to eliminate them, because they are meaningful, but we want to abstract away from the individual numbers. In addition, we might want to get rid of some other things like parentheticals and quotes, becayse these impossible for our model to keep track of given it's amount of memory. We can take care of these things in the preprocessing function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b11df",
   "metadata": {},
   "source": [
    "Here is a final version of our class with all the bells and whistles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e46957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk import ConditionalFreqDist\n",
    "from nltk.probability import ConditionalProbDist, ELEProbDist\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from functools import reduce\n",
    "\n",
    "class NgramModel():\n",
    "\n",
    "    \n",
    "    def __init__(self, corpus, n):\n",
    "        self.n = n\n",
    "        tokenized_corpus = self._tokenize(corpus)\n",
    "        self._ngrams = self._build_ngrams(tokenized_corpus, n)\n",
    "        self._cpd = self._build_distribution(self._ngrams, n)        \n",
    "\n",
    "    def _tokenize(self, corpus):\n",
    "        # The list of regular expressions and replacements to be applied\n",
    "        # the order here matters! these replacements will happen in order\n",
    "        replacements = [\n",
    "             [\"[-\\n]\",                   \" \"] # Hyphens to whitespace\n",
    "            ,[r'[][(){}#$%\"]',           \"\"] # Strip unwanted characters like quotes and brackets\n",
    "            ,[r'\\s([./-]?\\d+)+[./-]?\\s', \" [NUMBER] \"] # Standardize numbers\n",
    "            ,[r'\\.{3,}',                 \" [ELLIPSIS] \"] # remove ellipsis\n",
    "            ,[r'(\\w)([.,?!;:])',         r'\\1 \\2' ]  # separate punctuation from previous word\n",
    "        ]\n",
    "        \n",
    "        # This is a function that applies a single replacement from the list\n",
    "        resub = lambda words, repls: re.sub(repls[0], repls[1], words)\n",
    "        \n",
    "        # we use the resub function to applea each replacement to the entire corpus,\n",
    "        normalized_corpus = reduce(resub, replacements, corpus)\n",
    "        \n",
    "        \n",
    "        sentences = normalized_corpus.split('.')\n",
    "        \n",
    "        tokens = []\n",
    "        for sentence in sentences:\n",
    "            words = sentence.split() # split on whitespace\n",
    "            words = [word.lower() for word in words]\n",
    "            words = list(pad_both_ends(words, n=self.n))\n",
    "            tokens += words\n",
    "        \n",
    "        return tokens\n",
    "            \n",
    "    def _build_ngrams(self, tokenized_corpus, n):\n",
    "        n_grams = []\n",
    "        for i in range(n-1, len(tokenized_corpus)): \n",
    "            n_grams.append(tuple(tokenized_corpus[i-(n-1):i+1]))    \n",
    "        return n_grams\n",
    "    \n",
    "    def _build_distribution(self, corpus, n):\n",
    "               \n",
    "        cfd = ConditionalFreqDist()\n",
    "        for ngram in self._ngrams:\n",
    "            condition = tuple(ngram[0:n-1]) \n",
    "            outcome = ngram[n-1]\n",
    "            \n",
    "            cfd[condition][outcome] += 1\n",
    "        bins = len(cfd) # we have to pass the number of bins in our freq dist in as a parameter to probability distribution, so we have a bin for every word\n",
    "        cpd = ConditionalProbDist(cfd, ELEProbDist, bins)\n",
    "        self.cpd = cpd\n",
    "        return cpd\n",
    "        \n",
    "    def generate(self, num_sentences = 1, seed = []):\n",
    "        \"\"\"\n",
    "        There are two cases to deal with here. Either we have a start string, or we don't. \n",
    "        If we are given a start string, we'll have to find the last n-1 gram and condition on that\n",
    "        If we are not, we need to generate the first n-1 gram. For a trigram model, we need a bigram. But how can we use our model to generate new words when we have fewer than two words to condition on?\n",
    "        We can use a bigram model! But wait. If we have a bigram model, how do we generate the first token without another token to condition on? \n",
    "        We can use a unigram model! \n",
    "        Recursion will save us here. Turns out the easiest way to do this will be to recursively construct an n-1gram model and store it in the main model.\n",
    "        And how can we \n",
    "        Either way, we need a seed condition to enter into the loop with.\n",
    "        \"\"\"\n",
    "\n",
    "        # place to put generated tokens\n",
    "        string = []\n",
    "\n",
    "        if seed:\n",
    "            string = string + (list(pad_sequence(seed, self.n, pad_left=True, pad_right=False, left_pad_symbol='<s>') ) )\n",
    "        else:\n",
    "            string = string + (list(pad_sequence('', self.n, pad_left=True, pad_right=False, left_pad_symbol='<s>') ) )\n",
    "        \n",
    "        for i in range(num_sentences):\n",
    "            next_token = tuple(string[-(self.n-1):])\n",
    "            \n",
    "            # keep generating tokens as long as we havent reached the stop sequence\n",
    "            while next_token != '</s>':\n",
    "                \n",
    "                # get the last n-1 tokens to condition on next\n",
    "                lessgram = tuple(string[-(self.n-1):])\n",
    "\n",
    "    \n",
    "                next_token = self.cpd[lessgram].generate()\n",
    "                string.append( next_token )\n",
    "\n",
    "        string = ' '.join(string)\n",
    "        string = add_stops(string)\n",
    "\n",
    "        return string\n",
    "\n",
    "    \n",
    "    def add_stops(string):\n",
    "        \"\"\"\n",
    "        function to convert the stop/start sequence back into periods.\n",
    "        strips all the sequences of any number of stop tokens followed by the some number of start tokens\n",
    "        and replaces them with a period.\n",
    "\n",
    "        then strips any remaining stop and start sequences (which will occur at the beginning and end of our entire generated sequence)\n",
    "        \"\"\"\n",
    "        string = re.sub(r\"</s>(?:\\s</s>)*\\s<s>(?:\\s<s>)*\", \".\", string)\n",
    "\n",
    "        string = re.sub(r\"(<s>\\s)+\", \"\", string) # initial tokens\n",
    "        string = re.sub(r\"(</s>)\", \"\", string) # final token\n",
    "\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf90c92-e6a7-4b97-98bc-c3faccc536d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stops(string):\n",
    "    \"\"\"\n",
    "    function to convert the stop/start sequence back into periods.\n",
    "    strips all the sequences of any number of stop tokens followed by the some number of start tokens\n",
    "    and replaces them with a period.\n",
    "\n",
    "    then strips any remaining stop and start sequences (which will occur at the beginning and end of our entire generated sequence)\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"</s>(?:\\s</s>)*\\s<s>(?:\\s<s>)*\", \".\", string)\n",
    "\n",
    "    string = re.sub(r\"(<s>\\s)+\", \"\", string) # initial tokens\n",
    "    string = re.sub(r\"(</s>)\", \"\", string) # final token\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5591a9ce",
   "metadata": {},
   "source": [
    "We try generating a 4-gram model with the King James Bible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b20358",
   "metadata": {},
   "source": [
    "Our model expects its training corpus in the form of a single string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1d6e2",
   "metadata": {},
   "source": [
    "# Let's do a mashup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c1a90",
   "metadata": {},
   "source": [
    "Intro to beautiful soup for scraping web text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23cb8e83-ebff-4192-a0b8-f2c925780b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"dream_journal.txt\"\n",
    "\n",
    "# Read the content of the file and store it in a variable\n",
    "with open(file_path, 'r') as file:\n",
    "    text_dream = file.read()\n",
    "\n",
    "# Now, the 'text_variable' holds the content of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e319cad7-bf60-439c-924a-a6461e088bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = NgramModel(text_dream, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e36090c-4912-49a0-91b7-f1a40b87bc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"she can get sunlight and shove them in french !** i'm trying to chase the camp . they've been placing creepy doll versions of other side of her pockets , i need to my partner knows what's going to abruptly join the ai track . big lots , speed walking through the audience their period stopped . i had to my yard , standing beside the ride . three dimensional layered with hands at a fucking bear trying to steal stuff in such a result , my friend comes from the camp [ellipsis] i'm at a woman take things we're salvaging \""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.generate(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86054ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4\n",
    "\n",
    "from bs4 import *\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://theanarchistlibrary.org/library/david-graeber-anarchy-in-a-manner-of-speaking'\n",
    "res = requests.get(url)\n",
    "html_page = res.text\n",
    "\n",
    "# Parse the source code using BeautifulSoup\n",
    "soup = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "# Extract the plain text content\n",
    "text = soup.get_text()\n",
    "\n",
    "# Print the plain text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbeb3711-c89e-468e-96f1-66530111c9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4\n",
    "\n",
    "from bs4 import *\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://theanarchistlibrary.org/library/laboria-cuboniks-xenofeminism'\n",
    "res = requests.get(url)\n",
    "html_page = res.text\n",
    "\n",
    "# Parse the source code using BeautifulSoup\n",
    "soup = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "# Extract the plain text content\n",
    "text2 = soup.get_text()\n",
    "\n",
    "# Print the plain text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e2e9bf-729a-46e9-90bc-0719551daddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"profane_quotes.txt\"\n",
    "\n",
    "# Read the content of the file and store it in a variable\n",
    "with open(file_path, 'r') as file:\n",
    "    text_profane = file.read()\n",
    "\n",
    "# Now, the 'text_variable' holds the content of the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a408e09d-4c49-44fe-ae1e-71fb8a6d0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"chiang.txt\"\n",
    "\n",
    "# Read the content of the file and store it in a variable\n",
    "with open(file_path, 'r') as file:\n",
    "    text_chiang = file.read()\n",
    "\n",
    "# Now, the 'text_variable' holds the content of the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f0e008-5f46-49e0-a5c5-525d8e3e8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"gex.txt\"\n",
    "\n",
    "# Read the content of the file and store it in a variable\n",
    "with open(file_path, 'r') as file:\n",
    "    text_gex = file.read()\n",
    "\n",
    "# Now, the 'text_variable' holds the content of the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c57d0783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3656\n",
      "5330\n",
      "31980\n"
     ]
    }
   ],
   "source": [
    "print(len(text_gex))\n",
    "print(len(text_profane))\n",
    "print(len(text_profane * 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f269771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mashup = text_gex + text_profane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1277f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NgramModel(mashup, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a024dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"otherwise , never lost a fight , bite your boots and now on the compression i'll haunt your hit me talk yo' face swipe your mission , seven days a doge , feeling like pain if i got a thing that shit jobs that thing like oh , no way to refuse work before a way to society ; it's just to tell him some' to make love , kill policemen , look , he's a dive tie me with some whores cardi b , seven days a nigga , before a way similar . the bar i felt the blood on this ring ayy , the phone is between jobs :' since people are you let me up 'fore he can't bang you to believe in a disguise i couldn't go i'll never tell him 'fore he fuck me yeah , that's where to think that's ok doing now on his mind is only reason i wear a thing like his credit card hop on top , come take a phone just playin' you made his mind and poverty of words when it is comprehensible to bear in the bone good shit jobs :' since people are paid and you made his mic' and you yet again that shit but i could make me with some whores cardi b , i tell him on that saying no way to be done and you're lookin' for pictures of my dog's a thing like i'm the phone , doing now but that's a henny drink , the revolution . i ever say you write it get inside spit , i tell him some' to be i tell you can't bang you goodbye i said certified freak , just that are usually not at my hand , i couldn't go for walks , whose is fire , seven days a kegel while you circled me up like the workers who do a beating in public , pointless and it's just playin' you fucked up i bring up 'fore you to society ; it's not enough you made it up i couldn't go for pictures of the top , yeah i wear a provocation . they prefer to music , and you inside you goodbye i run down a king cobra with your lip ask for this song you'll never lost a hook in public , catch a beard , drip down on the top , ah yeah quick , there being a freak bitch , doing now on top , wap , doing shit but let me on top , come take my mind is wet it cream , you to make me on that shit better off if he can't bang you get a deep stroke i didn't even get your coat for walks , smoke , lame journalists , i'm surprised let's role play , and now from the latter as shit up your coat for pictures of the cops is because the yard smoking cigs in it all i will refer to refuse work that you to think that's ok my rope ? go beyond their control , look , kill time i will refer to think of this wet , kill judges , the mental asylum . they're just sing along you get to the bar i need a 1 , seven days a fight , got a garden snake , that's where to offer excellent working conditions \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b4a1cac-6e36-49f2-bf83-8a9054e4b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"carly.txt\"\n",
    "\n",
    "# Read the content of the file and store it in a variable\n",
    "with open(file_path, 'r') as file:\n",
    "    text_carly = file.read()\n",
    "\n",
    "# Now, the 'text_variable' holds the content of the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fae70d2-be2b-4057-b115-43ed97ecb0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"duncan.txt\"\n",
    "\n",
    "# Read the content of the file and store it in a variable\n",
    "with open(file_path, 'r') as file:\n",
    "    text_duncan = file.read()\n",
    "\n",
    "# Now, the 'text_variable' holds the content of the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "933f53d3-0d85-473b-ab7c-3d6211d5e4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15332\n",
      "37635\n",
      "30664\n"
     ]
    }
   ],
   "source": [
    "print(len(text_carly))\n",
    "print(len(text_chiang))\n",
    "print(len(text_carly * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d975b8e4-4db5-4d2a-bae9-cc2bcc76367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mashup2 = text_carly * 3 + text_chiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1945446e-d89d-4d32-bb0e-40f8242ae736",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = NgramModel(mashup2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9118aee4-6142-4bfd-ba3b-ef852f6d5b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"at last bit of us from ours ? hey , the memory was locked in my chest . the shadow of the limbs will assume that all life is far beyond any other , as an hour to reconstruct the point . with a thread , and replacing our universe as if they needed to discuss the empty lungs with me , i quit smoking those cigarettes but all pressure it on occasion , i realized that maybe ? it's like it's in fatal flaw . one another bad dreams get into the source of its public squares and no less force exerted as persistent currents generated within our movements depended on foil pages visible , the tumult of my relationship with this annual celebration , struggling against the edge of finding the flow of absolute equilibrium . reprinted by contrast , for they worked my initial auto dissection was made \""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.generate(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b27e221-cc68-4265-adf4-f06861370225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"omelas.txt\"\n",
    "\n",
    "# Read the content of the file and store it in a variable\n",
    "with open(file_path, 'r') as file:\n",
    "    text_omelas = file.read()\n",
    "\n",
    "# Now, the 'text_variable' holds the content of the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c78b9406-4ffc-4430-97ec-19f3130ec935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"chiang.txt\"\n",
    "\n",
    "# Read the content of the file and store it in a variable\n",
    "with open(file_path, 'r') as file:\n",
    "    text_chiang = file.read()\n",
    "\n",
    "# Now, the 'text_variable' holds the content of the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "293259a2-103b-4da8-a922-a666f287c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15546\n",
      "3656\n",
      "14624\n"
     ]
    }
   ],
   "source": [
    "print(len(text_omelas))\n",
    "print(len(text_gex))\n",
    "print(len(text_gex * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb3f50c3-5f7a-45ff-860b-d6dd9653d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "mashup3 = text_omelas + text_gex * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de626ac4-a9a1-44eb-923c-747eafdb13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = NgramModel(mashup3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0006fe0a-fb4a-4161-8788-9e4f05d12688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"but to most of mauve and chatting as you get the place even granted trains , parades , ok doing now it lives were mature , and it . “i will be proclaimed upon a description such as you like a city , impotence , bleh . omelas are between the child were vastly excited , join the racecourse are perhaps it with frightened , of a day or genitals , baby brand new mercedes i've been at least , crying 'bout , stand up into the ways of its legs , between the unnecessary but if you can't ever to see , small , could convince you circled me singing . “please let them neigh in . for help at night falls ; in rank along the beauty of sex beyond all but what i'm dead but the bitter injustice dry when it only animal who walk away from time \""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.generate(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363b0b1",
   "metadata": {},
   "source": [
    "Wow!\n",
    "\n",
    "'among the hills that are weaned from the waters saw thee polluted in thy glory above all people , from beersheba to mount up with . [number] : [number] and shaalabbin , and partly broken . report , that jehoshaphat the king is among us still believed in hope ; patient in spirit ; and half of thy power preserve thou those that served in the womb : if jacob take a lump of figs were set there upon him shall inherit all things thereon . in most militants this search for my gold and the lord separated the sons shall eat clean provender , which loveth thee and abishai , and kings have had dominion over our cattle . then he sacrificed also and to whomsoever he will prosper us ; thus have been occupied therein . yellowed figures of cherubims and palm trees : they serve not thy left side , upon their altars : but according to our hand be upon every fowl of the european union . all these did moses command joshua , this do ye look on us ; because a deep sleep fell upon it before saul : [number] wise men , let them turn their mourning . after theo’s rape , a strong wind ? [number] : [number] open thou mine affliction . to him remaining . rather comically , he took counsel how they might attain to innocency ? [number] : [number] for behold the place hormah  '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646db1d",
   "metadata": {},
   "source": [
    "# Exercise / Homework??\n",
    "\n",
    "Make a mashup of two texts. They can be texts you wrote (a collection of tweets, an essay), or from anywhere. You can use libgen to find books and Calibre to convert them to text. Either paste the text directly into a notebook or use a Python utility for reading files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15494939",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpiss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m alice \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mcorpiss\u001b[49m\u001b[38;5;241m.\u001b[39mgutenberg\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcarroll-alice.txt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      2\u001b[0m now \u001b[38;5;241m=\u001b[39m text\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(alice))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpiss' is not defined"
     ]
    }
   ],
   "source": [
    "alice = (' ').join(corpiss.gutenberg.words('carroll-alice.txt'))\n",
    "now = text\n",
    "\n",
    "print(len(alice))\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1125b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mashups = alice + text\n",
    "model = NgramModel(mashups, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd1a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9cef5",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "most used: \n",
    "* https://notebook.community/luketurner/ipython-notebooks/notebooks/n-gram%20tutorial\n",
    "* https://medium.com/analytics-vidhya/a-comprehensive-guide-to-build-your-own-language-model-in-python-5141b3917d6d\n",
    "* https://towardsdatascience.com/simulating-text-with-markov-chains-in-python-1a27e6d13fc6\n",
    "\n",
    "others:\n",
    "* https://eliteai-coep.medium.com/building-n-gram-language-model-from-scratch-9a5ec206b520\n",
    "* https://github.com/joshualoehr/ngram-language-model/blob/master/language_model.py\n",
    "* http://www.pygaze.org/2016/03/how-to-code-twitter-bot/\n",
    "    - code: https://github.com/esdalmaijer/markovbot\n",
    "* https://towardsdatascience.com/implementing-a-character-level-trigram-language-model-from-scratch-in-python-27ca0e1c3c3f"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
